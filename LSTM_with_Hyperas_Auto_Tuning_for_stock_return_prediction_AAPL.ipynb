{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "LSTM with Hyperas - Auto Tuning for stock return prediction - AAPL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Musyfy/AI_FIN_823/blob/master/LSTM_with_Hyperas_Auto_Tuning_for_stock_return_prediction_AAPL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaVRAWDTJ7x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make sure you comment out pip install hyperas after running "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lfWlp_nkXFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install tensorflow==1.15rc0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcra-dw0yh-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install hyperas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u00R59d-yvHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import dask.dataframe as dd\n",
        "import tensorflow.compat.v2 as tf\n",
        "import sys\n",
        "\n",
        "import keras as ks\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Dense, Conv1D, MaxPool2D, Flatten, Dropout, CuDNNLSTM, CuDNNGRU, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from keras.optimizers import Adam, SGD, Nadam\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from time import time\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.python.client import device_lib\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler , MinMaxScaler, scale,Normalizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "import random as rn\n",
        "\n",
        "import pandas_datareader.data as pd_reader\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdNNG5y-fePA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(37)\n",
        "\n",
        "# Setting the seed for python random numbers\n",
        "rn.seed(1254)\n",
        "\n",
        "# Setting the graph-level random seed.\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYnpU-ai-DQa",
        "colab_type": "code",
        "outputId": "fe57f4b8-5a36-4b90-b88e-f156d6c6cb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from platform import python_version\n",
        "print(python_version())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsHP0KzBy7Kk",
        "colab_type": "code",
        "outputId": "81f01f1a-525b-49cc-d4c4-10cbbf9b92e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%ls /gdrive"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx9aBM9hzH8m",
        "colab_type": "code",
        "outputId": "e093e804-469f-4dea-ffaa-0194f21216ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!ls '/gdrive/My Drive/Colab Notebooks'"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Copy of LSTM with Hyperas - Auto Tuning for stock return prediction - APPL.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock price prediction - AT&T.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock price prediction - BAC.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock price prediction - BACV2.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock price prediction-Copy1.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock price prediction - DIS.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock price prediction - MA.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock price prediction - PG.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock price prediction - UNH.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock price prediction - Visa.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock price prediction - XOM.ipynb'\n",
            "'LSTM with Hyperas - Auto Tuning for stock return prediction - APPL.ipynb'\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN7WLcr1yh-d",
        "colab_type": "code",
        "outputId": "3e9c7232-d8ca-403a-fb0d-b37d41822955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "## add company ticker\n",
        "company = 'AAPL'\n",
        "data = pd_reader.DataReader(\n",
        "     '{}'.format(company),\n",
        "     'yahoo')\n",
        "data = data[['Adj Close','High','Open','Low','Volume']]\n",
        "data[\"return\"] = np.log(1+((data[\"Adj Close\"]-data[\"Adj Close\"].shift(1))/data[\"Adj Close\"].shift(1)))\n",
        "data = data.dropna()\n",
        "factor_ratio = 0.7\n",
        "data_1 = data.iloc[:round(len(data)*factor_ratio)]\n",
        "data_2 = data[round(len(data)*factor_ratio):]\n",
        "data.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Open</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>return</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>26.647457</td>\n",
              "      <td>30.798571</td>\n",
              "      <td>30.657143</td>\n",
              "      <td>30.464285</td>\n",
              "      <td>150476200.0</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>26.223597</td>\n",
              "      <td>30.747143</td>\n",
              "      <td>30.625713</td>\n",
              "      <td>30.107143</td>\n",
              "      <td>138040000.0</td>\n",
              "      <td>-0.016034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>26.175119</td>\n",
              "      <td>30.285715</td>\n",
              "      <td>30.250000</td>\n",
              "      <td>29.864286</td>\n",
              "      <td>119282800.0</td>\n",
              "      <td>-0.001850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>26.349140</td>\n",
              "      <td>30.285715</td>\n",
              "      <td>30.042856</td>\n",
              "      <td>29.865715</td>\n",
              "      <td>111902700.0</td>\n",
              "      <td>0.006626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-11</th>\n",
              "      <td>26.116703</td>\n",
              "      <td>30.428572</td>\n",
              "      <td>30.400000</td>\n",
              "      <td>29.778572</td>\n",
              "      <td>115557400.0</td>\n",
              "      <td>-0.008861</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Adj Close       High       Open        Low       Volume    return\n",
              "Date                                                                         \n",
              "2010-01-05  26.647457  30.798571  30.657143  30.464285  150476200.0  0.001727\n",
              "2010-01-06  26.223597  30.747143  30.625713  30.107143  138040000.0 -0.016034\n",
              "2010-01-07  26.175119  30.285715  30.250000  29.864286  119282800.0 -0.001850\n",
              "2010-01-08  26.349140  30.285715  30.042856  29.865715  111902700.0  0.006626\n",
              "2010-01-11  26.116703  30.428572  30.400000  29.778572  115557400.0 -0.008861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA3QF3AFyh-g",
        "colab_type": "text"
      },
      "source": [
        "### Make sure to edit your stock ticker in def data()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnPMfRrTyh-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ADD COMPANY TICKER\n",
        "def data():\n",
        "  company = 'AAPL'\n",
        "  data = pd_reader.DataReader(\n",
        "    '{}'.format(company),\n",
        "    'yahoo')\n",
        "  data = data[['Adj Close','High','Open','Low','Volume']]\n",
        "  data[\"return\"] = np.log(1+((data[\"Adj Close\"]-data[\"Adj Close\"].shift(1))/data[\"Adj Close\"].shift(1)))\n",
        "  data = data.dropna()\n",
        "  factor_ratio = 0.7\n",
        "  data_1 = data.iloc[:round(len(data)*factor_ratio)]\n",
        "  data_2 = data[round(len(data)*factor_ratio):]\n",
        "\n",
        "  ###############################################\n",
        "  ##  Feature engineering construct the retrun ##\n",
        "  ###############################################\n",
        "  training_set = data_1.iloc[:,0:-1].values\n",
        "  y_set = data_1[\"return\"].values\n",
        "  y_set = y_set.reshape(-1,1)\n",
        "  sc = MinMaxScaler()\n",
        "  #training_set_scaled =training_set\n",
        "  \n",
        "  y_set_scaled=y_set\n",
        "  training_set_scaled = sc.fit_transform(training_set)\n",
        "  #y_set_scaled = sc.fit_transform(y_set)\n",
        "\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "\n",
        "  for i in range(45, len(training_set_scaled)):\n",
        "    X_train.append(training_set[i-45:i])\n",
        "    y_train.append(y_set_scaled[i][0])\n",
        "\n",
        "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "  X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 5))\n",
        "  \n",
        "  #test set\n",
        "  y_test = data_2['return'].values\n",
        "\n",
        "  dataset_total = data.iloc[:,0:-1]\n",
        "  inputs = dataset_total[len(dataset_total) - len(data_2) -45:].values\n",
        "  inputs = sc.fit_transform(inputs)\n",
        "\n",
        "  X_test = []\n",
        "  for i in range(45, len(inputs)):\n",
        "    X_test.append(inputs[i-45:i])\n",
        "  \n",
        "  X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "  X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 5))\n",
        "  \n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE0Zay3syh-i",
        "colab_type": "code",
        "outputId": "83394478-bfa9-4cfb-8860-8c6e327ac54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, y_train, X_test, y_test = data()\n",
        "X_train.shape[1],5"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCBEfWOIyh-k",
        "colab_type": "text"
      },
      "source": [
        "### Things to consider \n",
        "1. create_model function: Change epochs to a lower number in the beginning\n",
        "2. create_model function: Start with lower number of layers - 4 was the best for me \n",
        "3. create_model function: The number of hidden layers is still to be tuned manually \n",
        "4. create_model function: if you are to add more layers. Make sure that the last layer is always set to (return_sequence=False) \n",
        "5. create_model function: you can add more parameters to tune: such as activation function, add more optimizers, or change dropout rate to a range between 0 & 1. \n",
        "6. if __name__ == '__main__' function: Make sure notebook_name matches the name of your notebook, otherwise it doesn't run. not sure how it would work on pycharm (you can try to remove this parameter) \n",
        "7. if __name__ == '__main__' function: you can change the number of max_eval to a lower number if you want this to run faster. This parameter is similar to a random search, and  will give you different models based on the max_eval number chosen. 3 or 4 should be okay with what I have seen so far. \n",
        "\n",
        "**This will take time if you are running it on your local machine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pweGTr00yh-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(X_train, y_train, X_test, y_test): \n",
        "\n",
        "  \"\"\"\n",
        "  Model providing function:\n",
        "\n",
        "  Create Keras model with double curly brackets dropped-in as needed.\n",
        "  Return value has to be a valid python dictionary with two customary keys:\n",
        "      - loss: Specify a numeric evaluation metric to be minimized\n",
        "      - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
        "  The last one is optional, though recommended, namely:\n",
        "      - model: specify the model just created so that we can later use it again.\n",
        "  \"\"\"\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units={{choice([100, 200, 300])}}, input_shape=(45,5),go_backwards= True, return_sequences= True))\n",
        "  model.add(Dropout(rate={{uniform(0.01, 0.09)}}))\n",
        "  \n",
        "  model.add(LSTM(units={{choice([100, 200, 300])}}, return_sequences= False))\n",
        "  model.add(Dropout(rate={{uniform(0.01, 0.09)}}))\n",
        "  \n",
        "  #model.add(LSTM(units={{choice([100, 200, 300])}},go_backwards= True, return_sequences= False))\n",
        "  #model.add(Dropout(rate={{uniform(0.1, 0.9)}}))\n",
        "\n",
        "  #model.add(LSTM(units={{choice([100, 200, 300])}}, return_sequences= False))\n",
        "  #model.add(Dropout(rate={{uniform(0.2, 0.5)}}))\n",
        "  \n",
        "  #model.add(LSTM(units={{choice([100, 200, 300])}}))\n",
        "  #model.add(Dropout(rate={{uniform(0.2, 0.5)}}))\n",
        "  \n",
        "  model.add(Dense({{choice([50, 10, 5])}}))\n",
        "  model.add(Dense({{choice([50, 10,5])}}))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(loss='mean_squared_error',\n",
        "                optimizer={{choice(['adam', 'sgd','rmsprop','adagrad'])}})\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  result = model.fit(X_train, y_train,\n",
        "            batch_size={{choice([100,50,80])}},\n",
        "            epochs=40, verbose=2)\n",
        "  #get the highest validation accuracy of the training epochs\n",
        "  validation_error = np.amin(result.history['loss']) \n",
        "  print('Best validation error of epoch:', validation_error)\n",
        "  return {'loss': -validation_error, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8WEn-d5yh-m",
        "colab_type": "code",
        "outputId": "1822fdca-feb8-4ec8-b392-9552f2dea01c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    best_run, best_model = optim.minimize(model=create_model,\n",
        "                                    data=data,\n",
        "                                    algo=tpe.suggest,\n",
        "                                    max_evals=1,\n",
        "                                    trials=Trials(),\n",
        "                                    notebook_name= os.path.join('..','gdrive','My Drive','Colab Notebooks','LSTM with Hyperas - Auto Tuning for stock return prediction - AAPL'))\n",
        "    X_train, Y_train, X_test, Y_test = data()\n",
        "    print(\"Evalutation of best performing model:\")\n",
        "    print(best_model)\n",
        "    print(\"Best performing model chosen hyper-parameters:\")\n",
        "    print(best_run)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pandas as pd\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import matplotlib.pyplot as plt\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from mpl_toolkits.mplot3d import Axes3D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import seaborn as sns\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tqdm import tqdm\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import dask.dataframe as dd\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import tensorflow as tf\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import sys\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import keras as ks\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import backend as K\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import metrics\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.recurrent import LSTM\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Conv1D, MaxPool2D, Flatten, Dropout, CuDNNLSTM, CuDNNGRU, Conv2D, MaxPooling2D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.optimizers import Adam, SGD, Nadam\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.normalization import BatchNormalization\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from time import time\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.python.client import device_lib\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import np_utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.preprocessing import StandardScaler, MinMaxScaler, scale, Normalizer\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pickle\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import random as rn\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pandas_datareader.data as pd_reader\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import warnings\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from platform import python_version\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import drive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pickle\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import files\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'units': hp.choice('units', [100, 200, 300]),\n",
            "        'rate': hp.uniform('rate', 0.01, 0.09),\n",
            "        'units_1': hp.choice('units_1', [100, 200, 300]),\n",
            "        'rate_1': hp.uniform('rate_1', 0.01, 0.09),\n",
            "        'units_2': hp.choice('units_2', [100, 200, 300]),\n",
            "        'rate_2': hp.uniform('rate_2', 0.1, 0.9),\n",
            "        'units_3': hp.choice('units_3', [100, 200, 300]),\n",
            "        'rate_3': hp.uniform('rate_3', 0.2, 0.5),\n",
            "        'units_4': hp.choice('units_4', [100, 200, 300]),\n",
            "        'rate_4': hp.uniform('rate_4', 0.2, 0.5),\n",
            "        'Dense': hp.choice('Dense', [50, 10, 5]),\n",
            "        'Dense_1': hp.choice('Dense_1', [50, 10,5]),\n",
            "        'optimizer': hp.choice('optimizer', ['adam', 'sgd','rmsprop','adagrad']),\n",
            "        'batch_size': hp.choice('batch_size', [100,50,80]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "   1: \n",
            "   2: company = 'AAPL'\n",
            "   3: data = pd_reader.DataReader(\n",
            "   4:   '{}'.format(company),\n",
            "   5:   'yahoo')\n",
            "   6: data = data[['Adj Close','High','Open','Low','Volume']]\n",
            "   7: data[\"return\"] = np.log(1+((data[\"Adj Close\"]-data[\"Adj Close\"].shift(1))/data[\"Adj Close\"].shift(1)))\n",
            "   8: data = data.dropna()\n",
            "   9: factor_ratio = 0.7\n",
            "  10: data_1 = data.iloc[:round(len(data)*factor_ratio)]\n",
            "  11: data_2 = data[round(len(data)*factor_ratio):]\n",
            "  12: \n",
            "  13: ###############################################\n",
            "  14: ##  Feature engineering construct the retrun ##\n",
            "  15: ###############################################\n",
            "  16: training_set = data_1.iloc[:,0:-1].values\n",
            "  17: y_set = data_1[\"return\"].values\n",
            "  18: y_set = y_set.reshape(-1,1)\n",
            "  19: sc = MinMaxScaler()\n",
            "  20: #training_set_scaled =training_set\n",
            "  21: \n",
            "  22: y_set_scaled=y_set\n",
            "  23: training_set_scaled = sc.fit_transform(training_set)\n",
            "  24: #y_set_scaled = sc.fit_transform(y_set)\n",
            "  25: \n",
            "  26: X_train = []\n",
            "  27: y_train = []\n",
            "  28: \n",
            "  29: for i in range(45, len(training_set_scaled)):\n",
            "  30:   X_train.append(training_set[i-45:i])\n",
            "  31:   y_train.append(y_set_scaled[i][0])\n",
            "  32: \n",
            "  33: X_train, y_train = np.array(X_train), np.array(y_train)\n",
            "  34: X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 5))\n",
            "  35: \n",
            "  36: #test set\n",
            "  37: y_test = data_2['return'].values\n",
            "  38: \n",
            "  39: dataset_total = data.iloc[:,0:-1]\n",
            "  40: inputs = dataset_total[len(dataset_total) - len(data_2) -45:].values\n",
            "  41: inputs = sc.fit_transform(inputs)\n",
            "  42: \n",
            "  43: X_test = []\n",
            "  44: for i in range(45, len(inputs)):\n",
            "  45:   X_test.append(inputs[i-45:i])\n",
            "  46: \n",
            "  47: X_test, y_test = np.array(X_test), np.array(y_test)\n",
            "  48: X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 5))\n",
            "  49: \n",
            "  50: \n",
            "  51: \n",
            "  52: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3: \n",
            "   4:   \"\"\"\n",
            "   5:   Model providing function:\n",
            "   6: \n",
            "   7:   Create Keras model with double curly brackets dropped-in as needed.\n",
            "   8:   Return value has to be a valid python dictionary with two customary keys:\n",
            "   9:       - loss: Specify a numeric evaluation metric to be minimized\n",
            "  10:       - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
            "  11:   The last one is optional, though recommended, namely:\n",
            "  12:       - model: specify the model just created so that we can later use it again.\n",
            "  13:   \"\"\"\n",
            "  14: \n",
            "  15:   model = Sequential()\n",
            "  16:   model.add(LSTM(units=space['units'], input_shape=(45,5),go_backwards= True, return_sequences= True))\n",
            "  17:   model.add(Dropout(rate=space['rate']))\n",
            "  18:   \n",
            "  19:   model.add(LSTM(units=space['units_1'], return_sequences= False))\n",
            "  20:   model.add(Dropout(rate=space['rate_1']))\n",
            "  21:   \n",
            "  22:   #model.add(LSTM(units=space['units_2'],go_backwards= True, return_sequences= False))\n",
            "  23:   #model.add(Dropout(rate=space['rate_2']))\n",
            "  24: \n",
            "  25:   #model.add(LSTM(units=space['units_3'], return_sequences= False))\n",
            "  26:   #model.add(Dropout(rate=space['rate_3']))\n",
            "  27:   \n",
            "  28:   #model.add(LSTM(units=space['units_4']))\n",
            "  29:   #model.add(Dropout(rate=space['rate_4']))\n",
            "  30:   \n",
            "  31:   model.add(Dense(space['Dense']))\n",
            "  32:   model.add(Dense(space['Dense_1']))\n",
            "  33:   model.add(Dense(1))\n",
            "  34: \n",
            "  35:   model.compile(loss='mean_squared_error',\n",
            "  36:                 optimizer=space['optimizer'])\n",
            "  37: \n",
            "  38:   model.summary()\n",
            "  39: \n",
            "  40:   result = model.fit(X_train, y_train,\n",
            "  41:             batch_size=space['batch_size'],\n",
            "  42:             epochs=40, verbose=2)\n",
            "  43:   #get the highest validation accuracy of the training epochs\n",
            "  44:   validation_error = np.amin(result.history['loss']) \n",
            "  45:   print('Best validation error of epoch:', validation_error)\n",
            "  46:   return {'loss': -validation_error, 'status': STATUS_OK, 'model': model}\n",
            "  47: \n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_13 (LSTM)               (None, 45, 200)           164800    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 45, 200)           0         \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 300)               601200    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 5)                 1505      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 767,576\n",
            "Trainable params: 767,576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            " - 7s - loss: 0.1692\n",
            "\n",
            "Epoch 2/40\n",
            " - 3s - loss: 0.0054\n",
            "\n",
            "Epoch 3/40\n",
            " - 4s - loss: 0.0010\n",
            "\n",
            "Epoch 4/40\n",
            " - 4s - loss: 5.9579e-04\n",
            "\n",
            "Epoch 5/40\n",
            " - 4s - loss: 5.3333e-04\n",
            "\n",
            "Epoch 6/40\n",
            " - 4s - loss: 5.8579e-04\n",
            "\n",
            "Epoch 7/40\n",
            " - 3s - loss: 5.2358e-04\n",
            "\n",
            "Epoch 8/40\n",
            " - 3s - loss: 5.2017e-04\n",
            "\n",
            "Epoch 9/40\n",
            " - 3s - loss: 5.1155e-04\n",
            "\n",
            "Epoch 10/40\n",
            " - 3s - loss: 5.3364e-04\n",
            "\n",
            "Epoch 11/40\n",
            " - 3s - loss: 5.1686e-04\n",
            "\n",
            "Epoch 12/40\n",
            " - 3s - loss: 5.0607e-04\n",
            "\n",
            "Epoch 13/40\n",
            " - 3s - loss: 4.9460e-04\n",
            "\n",
            "Epoch 14/40\n",
            " - 3s - loss: 4.9979e-04\n",
            "\n",
            "Epoch 15/40\n",
            " - 3s - loss: 5.2290e-04\n",
            "\n",
            "Epoch 16/40\n",
            " - 3s - loss: 4.8244e-04\n",
            "\n",
            "Epoch 17/40\n",
            " - 3s - loss: 4.8624e-04\n",
            "\n",
            "Epoch 18/40\n",
            " - 3s - loss: 4.8334e-04\n",
            "\n",
            "Epoch 19/40\n",
            " - 3s - loss: 4.6320e-04\n",
            "\n",
            "Epoch 20/40\n",
            " - 3s - loss: 4.3386e-04\n",
            "\n",
            "Epoch 21/40\n",
            " - 3s - loss: 4.6652e-04\n",
            "\n",
            "Epoch 22/40\n",
            " - 3s - loss: 4.7506e-04\n",
            "\n",
            "Epoch 23/40\n",
            " - 3s - loss: 4.3344e-04\n",
            "\n",
            "Epoch 24/40\n",
            " - 4s - loss: 4.4421e-04\n",
            "\n",
            "Epoch 25/40\n",
            " - 3s - loss: 4.5732e-04\n",
            "\n",
            "Epoch 26/40\n",
            " - 3s - loss: 4.1687e-04\n",
            "\n",
            "Epoch 27/40\n",
            " - 3s - loss: 4.5546e-04\n",
            "\n",
            "Epoch 28/40\n",
            " - 3s - loss: 4.3540e-04\n",
            "\n",
            "Epoch 29/40\n",
            " - 4s - loss: 3.9688e-04\n",
            "\n",
            "Epoch 30/40\n",
            " - 4s - loss: 4.1375e-04\n",
            "\n",
            "Epoch 31/40\n",
            " - 4s - loss: 4.0169e-04\n",
            "\n",
            "Epoch 32/40\n",
            " - 4s - loss: 4.0830e-04\n",
            "\n",
            "Epoch 33/40\n",
            " - 4s - loss: 4.1713e-04\n",
            "\n",
            "Epoch 34/40\n",
            " - 4s - loss: 3.7751e-04\n",
            "\n",
            "Epoch 35/40\n",
            " - 3s - loss: 4.0548e-04\n",
            "\n",
            "Epoch 36/40\n",
            " - 3s - loss: 3.7020e-04\n",
            "\n",
            "Epoch 37/40\n",
            " - 3s - loss: 3.8176e-04\n",
            "\n",
            "Epoch 38/40\n",
            " - 3s - loss: 3.8166e-04\n",
            "\n",
            "Epoch 39/40\n",
            " - 3s - loss: 3.7705e-04\n",
            "\n",
            "Epoch 40/40\n",
            " - 3s - loss: 3.9641e-04\n",
            "\n",
            "Best validation error of epoch:\n",
            "0.0003701972780222802\n",
            "100%|██████████| 1/1 [02:20<00:00, 140.71s/it, best loss: -0.0003701972780222802]\n",
            "Evalutation of best performing model:\n",
            "<keras.engine.sequential.Sequential object at 0x7f284d962d68>\n",
            "Best performing model chosen hyper-parameters:\n",
            "{'Dense': 2, 'Dense_1': 1, 'batch_size': 2, 'optimizer': 0, 'rate': 0.07582744887138203, 'rate_1': 0.015229584243240595, 'rate_2': 0.114254892109782, 'rate_3': 0.45350896294219734, 'rate_4': 0.38326289278437076, 'units': 1, 'units_1': 2, 'units_2': 0, 'units_3': 1, 'units_4': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyo4NHdqyh-n",
        "colab_type": "code",
        "outputId": "68cd2b5d-3ca2-4382-bf88-d64f9163efe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "best_run"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dense': 2,\n",
              " 'Dense_1': 1,\n",
              " 'batch_size': 2,\n",
              " 'optimizer': 0,\n",
              " 'rate': 0.07582744887138203,\n",
              " 'rate_1': 0.015229584243240595,\n",
              " 'rate_2': 0.114254892109782,\n",
              " 'rate_3': 0.45350896294219734,\n",
              " 'rate_4': 0.38326289278437076,\n",
              " 'units': 1,\n",
              " 'units_1': 2,\n",
              " 'units_2': 0,\n",
              " 'units_3': 1,\n",
              " 'units_4': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7ZzZ2-PHyh-p",
        "colab_type": "code",
        "outputId": "455e0890-89aa-4cbb-e344-75035ea87ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "best_model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_13 (LSTM)               (None, 45, 200)           164800    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 45, 200)           0         \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 300)               601200    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 5)                 1505      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 767,576\n",
            "Trainable params: 767,576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLJZi8Hjyh-q",
        "colab_type": "text"
      },
      "source": [
        "## Make sure to edit your stock ticker again in the next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa_aX3gvyh-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##maka sure to change the stock ticker here \n",
        "## add company ticker\n",
        "company = 'AAPL'\n",
        "data = pd_reader.DataReader(\n",
        "     '{}'.format(company),\n",
        "     'yahoo')\n",
        "data = data[['Adj Close','High','Open','Low','Volume']]\n",
        "data[\"return\"] = np.log(1+((data[\"Adj Close\"]-data[\"Adj Close\"].shift(1))/data[\"Adj Close\"].shift(1)))\n",
        "data = data.dropna()\n",
        "factor_ratio = 0.7\n",
        "data_1 = data.iloc[:round(len(data)*factor_ratio)]\n",
        "data_2 = data[round(len(data)*factor_ratio):]\n",
        " \n",
        "training_set = data_1.iloc[:,0:-1].values\n",
        "y_set = data_1[\"return\"].values\n",
        "y_set = y_set.reshape(-1,1)\n",
        "sc = MinMaxScaler()\n",
        "y_set_scaled = y_set\n",
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alb_Bonxyh-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_stock_price = data_2['return'].values\n",
        "\n",
        "dataset_total = data.iloc[:,0:-1]\n",
        "inputs = dataset_total[len(dataset_total) - len(data_2) -45:].values\n",
        "inputs = sc.fit_transform(inputs)\n",
        "\n",
        "X_test = []\n",
        "for i in range(45, len(inputs)):\n",
        "    X_test.append(inputs[i-45:i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "414zI9ISyh-s",
        "colab_type": "code",
        "outputId": "086acdeb-a730-4aee-d605-2d44cdff5ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 5))\n",
        "X_test.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(758, 45, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VaNcjScYyh-v",
        "colab_type": "code",
        "outputId": "1eab7512-0d1e-4b53-9c72-4bb312abd639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predicted_stock_price= best_model.predict(X_test)\n",
        "predicted_stock = pd.DataFrame(predicted_stock_price,columns=['perdict return'])\n",
        "real_stock = pd.DataFrame(real_stock_price,columns=['real return'])\n",
        "data_test = data[round(len(data)*factor_ratio):]\n",
        "data_test.reset_index(inplace=True)\n",
        "data_test = data_test[['Date']]\n",
        "\n",
        "inal = pd.merge(real_stock, predicted_stock, left_index=True, right_index=True)\n",
        "final1 = pd.merge(data_test, final, left_index=True, right_index=True)\n",
        "final1.to_csv(\"{}.csv\".format(company))\n",
        "final['direction'] = final[\"real return\"]*final[\"perdict return\"]\n",
        "def iden(x):\n",
        "    if x >0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "final[\"hit\"] = final[\"direction\"].apply(lambda x:iden(x))\n",
        "print('hit ratio:{}'.format(final[\"hit\"].sum()/final[\"hit\"].count()))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hit ratio:0.5488126649076517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzElYx-nyh-x",
        "colab_type": "code",
        "outputId": "7be26ce0-2653-44de-be1b-dd931c0250c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(real_stock_price, color = 'black', label = '{} Stock Price'.format(company))\n",
        "plt.plot(predicted_stock_price, color = 'green', label = 'Predicted {} Stock return'.format(company))\n",
        "plt.title('{} Stock return Prediction'.format(company))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('{} Stock return'.format(company))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEO8DPvoGn2q",
        "colab_type": "code",
        "outputId": "9a623202-98bf-4666-b428-675fbb7bc595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import pickle\n",
        "with open('AAPL_model.pickle','wb') as f:\n",
        "    pickle.dump(best_model,f)\n",
        "\n",
        "with open('AAPL_model.pickle','rb') as f:\n",
        "    model = pickle.load(f)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.758274 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lbroo87JvWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('AAPL_model.pickle') \n",
        "files.download(\"AAPL.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}