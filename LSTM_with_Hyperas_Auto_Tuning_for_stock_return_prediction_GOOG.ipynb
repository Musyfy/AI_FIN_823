{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "LSTM with Hyperas - Auto Tuning for stock return prediction - GOOG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Musyfy/AI_FIN_823/blob/master/LSTM_with_Hyperas_Auto_Tuning_for_stock_return_prediction_GOOG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaVRAWDTJ7x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make sure you comment out pip install hyperas after running "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lfWlp_nkXFH",
        "colab_type": "code",
        "outputId": "3889485c-433d-47a8-f87a-fa3add0b1b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#pip install tensorflow==1.15rc0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15rc0 in /usr/local/lib/python3.6/dist-packages (1.15.0rc0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019090402,>=1.14.0.dev2019090401 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (1.14.0.dev2019090401)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (0.33.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (0.9.0)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a20190822,>=1.15.0a20190821 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (1.15.0a20190821)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (1.17.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15rc0) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190822,>=1.15.0a20190821->tensorflow==1.15rc0) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190822,>=1.15.0a20190821->tensorflow==1.15rc0) (42.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190822,>=1.15.0a20190821->tensorflow==1.15rc0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15rc0) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcra-dw0yh-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "bd4e9dce-c352-4d03-b633-8d4e3628defa"
      },
      "source": [
        "#pip install hyperas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/04/34/87ad6ffb42df9c1fa9c4c906f65813d42ad70d68c66af4ffff048c228cd4/hyperas-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.2.5)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.10.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (4.6.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.1.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (4.3.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.6.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.17.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.28.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert->hyperas) (4.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.3.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.8.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter->hyperas) (17.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter->hyperas) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (4.7.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (42.0.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.1.8)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->hyperas) (0.6.0)\n",
            "Installing collected packages: hyperas\n",
            "Successfully installed hyperas-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u00R59d-yvHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "12b20bea-6705-4f15-9ae5-7cb4917e0105"
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import dask.dataframe as dd\n",
        "import tensorflow.compat.v2 as tf\n",
        "import sys\n",
        "\n",
        "import keras as ks\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Dense, Conv1D, MaxPool2D, Flatten, Dropout, CuDNNLSTM, CuDNNGRU, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from keras.optimizers import Adam, SGD, Nadam\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from time import time\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.python.client import device_lib\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler , MinMaxScaler, scale,Normalizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "import random as rn\n",
        "\n",
        "import pandas_datareader.data as pd_reader\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdNNG5y-fePA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(37)\n",
        "\n",
        "# Setting the seed for python random numbers\n",
        "rn.seed(1254)\n",
        "\n",
        "# Setting the graph-level random seed.\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYnpU-ai-DQa",
        "colab_type": "code",
        "outputId": "9f697196-ebf1-4b08-d9bc-cd0a4a18afad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from platform import python_version\n",
        "print(python_version())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsHP0KzBy7Kk",
        "colab_type": "code",
        "outputId": "7e30e50a-eeac-4e07-bbd4-2637130f280b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%ls /gdrive"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx9aBM9hzH8m",
        "colab_type": "code",
        "outputId": "89ee10d4-f984-4a8a-c3f5-203dbc6423c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/gdrive/My Drive/Colab Notebooks'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'LSTM with Hyperas - Auto Tuning for stock return prediction - GOOG.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN7WLcr1yh-d",
        "colab_type": "code",
        "outputId": "6936aba1-c44c-45df-996c-fc308b8e6733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "## add company ticker\n",
        "company = 'GOOG'\n",
        "data = pd_reader.DataReader(\n",
        "     '{}'.format(company),\n",
        "     'yahoo')\n",
        "data = data[['Adj Close','High','Open','Low','Volume']]\n",
        "data[\"return\"] = np.log(1+((data[\"Adj Close\"]-data[\"Adj Close\"].shift(1))/data[\"Adj Close\"].shift(1)))\n",
        "data = data.dropna()\n",
        "factor_ratio = 0.7\n",
        "data_1 = data.iloc[:round(len(data)*factor_ratio)]\n",
        "data_2 = data[round(len(data)*factor_ratio):]\n",
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Open</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>return</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>310.829926</td>\n",
              "      <td>312.747742</td>\n",
              "      <td>312.418976</td>\n",
              "      <td>309.609497</td>\n",
              "      <td>6031900.0</td>\n",
              "      <td>-0.004413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>302.994293</td>\n",
              "      <td>311.761444</td>\n",
              "      <td>311.761444</td>\n",
              "      <td>302.047852</td>\n",
              "      <td>7987100.0</td>\n",
              "      <td>-0.025532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>295.940735</td>\n",
              "      <td>303.861053</td>\n",
              "      <td>303.562164</td>\n",
              "      <td>295.218445</td>\n",
              "      <td>12876600.0</td>\n",
              "      <td>-0.023555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>299.885956</td>\n",
              "      <td>300.498657</td>\n",
              "      <td>294.894653</td>\n",
              "      <td>293.455048</td>\n",
              "      <td>9483900.0</td>\n",
              "      <td>0.013243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-11</th>\n",
              "      <td>299.432648</td>\n",
              "      <td>301.101410</td>\n",
              "      <td>301.101410</td>\n",
              "      <td>295.910858</td>\n",
              "      <td>14479800.0</td>\n",
              "      <td>-0.001513</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Adj Close        High        Open         Low      Volume  \\\n",
              "Date                                                                     \n",
              "2010-01-05  310.829926  312.747742  312.418976  309.609497   6031900.0   \n",
              "2010-01-06  302.994293  311.761444  311.761444  302.047852   7987100.0   \n",
              "2010-01-07  295.940735  303.861053  303.562164  295.218445  12876600.0   \n",
              "2010-01-08  299.885956  300.498657  294.894653  293.455048   9483900.0   \n",
              "2010-01-11  299.432648  301.101410  301.101410  295.910858  14479800.0   \n",
              "\n",
              "              return  \n",
              "Date                  \n",
              "2010-01-05 -0.004413  \n",
              "2010-01-06 -0.025532  \n",
              "2010-01-07 -0.023555  \n",
              "2010-01-08  0.013243  \n",
              "2010-01-11 -0.001513  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA3QF3AFyh-g",
        "colab_type": "text"
      },
      "source": [
        "### Make sure to edit your stock ticker in def data()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnPMfRrTyh-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ADD COMPANY TICKER\n",
        "def data():\n",
        "  company = 'GOOG'\n",
        "  data = pd_reader.DataReader(\n",
        "    '{}'.format(company),\n",
        "    'yahoo')\n",
        "  data = data[['Adj Close','High','Open','Low','Volume']]\n",
        "  data[\"return\"] = np.log(1+((data[\"Adj Close\"]-data[\"Adj Close\"].shift(1))/data[\"Adj Close\"].shift(1)))\n",
        "  data = data.dropna()\n",
        "  factor_ratio = 0.7\n",
        "  data_1 = data.iloc[:round(len(data)*factor_ratio)]\n",
        "  data_2 = data[round(len(data)*factor_ratio):]\n",
        "\n",
        "  ###############################################\n",
        "  ##  Feature engineering construct the retrun ##\n",
        "  ###############################################\n",
        "  training_set = data_1.iloc[:,0:-1].values\n",
        "  y_set = data_1[\"return\"].values\n",
        "  y_set = y_set.reshape(-1,1)\n",
        "  sc = MinMaxScaler()\n",
        "  #training_set_scaled =training_set\n",
        "  \n",
        "  y_set_scaled=y_set\n",
        "  training_set_scaled = sc.fit_transform(training_set)\n",
        "  #y_set_scaled = sc.fit_transform(y_set)\n",
        "\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "\n",
        "  for i in range(45, len(training_set_scaled)):\n",
        "    X_train.append(training_set[i-45:i])\n",
        "    y_train.append(y_set_scaled[i][0])\n",
        "\n",
        "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "  X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 5))\n",
        "  \n",
        "  #test set\n",
        "  y_test = data_2['return'].values\n",
        "\n",
        "  dataset_total = data.iloc[:,0:-1]\n",
        "  inputs = dataset_total[len(dataset_total) - len(data_2) -45:].values\n",
        "  inputs = sc.fit_transform(inputs)\n",
        "\n",
        "  X_test = []\n",
        "  for i in range(45, len(inputs)):\n",
        "    X_test.append(inputs[i-45:i])\n",
        "  \n",
        "  X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "  X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 5))\n",
        "  \n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE0Zay3syh-i",
        "colab_type": "code",
        "outputId": "d0eff416-a12b-49f4-9046-bf9956387e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, y_train, X_test, y_test = data()\n",
        "X_train.shape[1],5"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCBEfWOIyh-k",
        "colab_type": "text"
      },
      "source": [
        "### Things to consider \n",
        "1. create_model function: Change epochs to a lower number in the beginning\n",
        "2. create_model function: Start with lower number of layers - 4 was the best for me \n",
        "3. create_model function: The number of hidden layers is still to be tuned manually \n",
        "4. create_model function: if you are to add more layers. Make sure that the last layer is always set to (return_sequence=False) \n",
        "5. create_model function: you can add more parameters to tune: such as activation function, add more optimizers, or change dropout rate to a range between 0 & 1. \n",
        "6. if __name__ == '__main__' function: Make sure notebook_name matches the name of your notebook, otherwise it doesn't run. not sure how it would work on pycharm (you can try to remove this parameter) \n",
        "7. if __name__ == '__main__' function: you can change the number of max_eval to a lower number if you want this to run faster. This parameter is similar to a random search, and  will give you different models based on the max_eval number chosen. 3 or 4 should be okay with what I have seen so far. \n",
        "\n",
        "**This will take time if you are running it on your local machine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pweGTr00yh-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(X_train, y_train, X_test, y_test): \n",
        "\n",
        "  \"\"\"\n",
        "  Model providing function:\n",
        "\n",
        "  Create Keras model with double curly brackets dropped-in as needed.\n",
        "  Return value has to be a valid python dictionary with two customary keys:\n",
        "      - loss: Specify a numeric evaluation metric to be minimized\n",
        "      - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
        "  The last one is optional, though recommended, namely:\n",
        "      - model: specify the model just created so that we can later use it again.\n",
        "  \"\"\"\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units={{choice([100, 200, 300])}}, input_shape=(45,5),go_backwards= True, return_sequences= True))\n",
        "  model.add(Dropout(rate={{uniform(0.01, 0.09)}}))\n",
        "  \n",
        "  model.add(LSTM(units={{choice([100, 200, 300])}}, return_sequences= False))\n",
        "  model.add(Dropout(rate={{uniform(0.01, 0.09)}}))\n",
        "  \n",
        "  #model.add(LSTM(units={{choice([100, 200, 300])}},go_backwards= True, return_sequences= False))\n",
        "  #model.add(Dropout(rate={{uniform(0.1, 0.9)}}))\n",
        "\n",
        "  #model.add(LSTM(units={{choice([100, 200, 300])}}, return_sequences= False))\n",
        "  #model.add(Dropout(rate={{uniform(0.2, 0.5)}}))\n",
        "  \n",
        "  #model.add(LSTM(units={{choice([100, 200, 300])}}))\n",
        "  #model.add(Dropout(rate={{uniform(0.2, 0.5)}}))\n",
        "  \n",
        "  model.add(Dense({{choice([50, 10, 5])}}))\n",
        "  model.add(Dense({{choice([50, 10,5])}}))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(loss='mean_squared_error',\n",
        "                optimizer={{choice(['adam', 'sgd','rmsprop','adagrad'])}})\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  result = model.fit(X_train, y_train,\n",
        "            batch_size={{choice([100,50,80])}},\n",
        "            epochs=40, verbose=2)\n",
        "  #get the highest validation accuracy of the training epochs\n",
        "  validation_error = np.amin(result.history['loss']) \n",
        "  print('Best validation error of epoch:', validation_error)\n",
        "  return {'loss': -validation_error, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8WEn-d5yh-m",
        "colab_type": "code",
        "outputId": "6227be92-5e7f-4d53-8855-42b96ba6d8d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    best_run, best_model = optim.minimize(model=create_model,\n",
        "                                    data=data,\n",
        "                                    algo=tpe.suggest,\n",
        "                                    max_evals=1,\n",
        "                                    trials=Trials(),\n",
        "                                    notebook_name= os.path.join('..','gdrive','My Drive','Colab Notebooks','LSTM with Hyperas - Auto Tuning for stock return prediction - GOOG'))\n",
        "    X_train, Y_train, X_test, Y_test = data()\n",
        "    print(\"Evalutation of best performing model:\")\n",
        "    print(best_model)\n",
        "    print(\"Best performing model chosen hyper-parameters:\")\n",
        "    print(best_run)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pandas as pd\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import matplotlib.pyplot as plt\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from mpl_toolkits.mplot3d import Axes3D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import seaborn as sns\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tqdm import tqdm\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import dask.dataframe as dd\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import tensorflow.compat.v2 as tf\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import sys\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import keras as ks\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import backend as K\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import metrics\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.recurrent import LSTM\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Conv1D, MaxPool2D, Flatten, Dropout, CuDNNLSTM, CuDNNGRU, Conv2D, MaxPooling2D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.optimizers import Adam, SGD, Nadam\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.normalization import BatchNormalization\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from time import time\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.python.client import device_lib\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import np_utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.preprocessing import StandardScaler, MinMaxScaler, scale, Normalizer\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pickle\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import random as rn\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pandas_datareader.data as pd_reader\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import warnings\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from platform import python_version\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import drive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pickle\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import files\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'units': hp.choice('units', [100, 200, 300]),\n",
            "        'rate': hp.uniform('rate', 0.01, 0.09),\n",
            "        'units_1': hp.choice('units_1', [100, 200, 300]),\n",
            "        'rate_1': hp.uniform('rate_1', 0.01, 0.09),\n",
            "        'units_2': hp.choice('units_2', [100, 200, 300]),\n",
            "        'rate_2': hp.uniform('rate_2', 0.1, 0.9),\n",
            "        'units_3': hp.choice('units_3', [100, 200, 300]),\n",
            "        'rate_3': hp.uniform('rate_3', 0.2, 0.5),\n",
            "        'units_4': hp.choice('units_4', [100, 200, 300]),\n",
            "        'rate_4': hp.uniform('rate_4', 0.2, 0.5),\n",
            "        'Dense': hp.choice('Dense', [50, 10, 5]),\n",
            "        'Dense_1': hp.choice('Dense_1', [50, 10,5]),\n",
            "        'optimizer': hp.choice('optimizer', ['adam', 'sgd','rmsprop','adagrad']),\n",
            "        'batch_size': hp.choice('batch_size', [100,50,80]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "   1: \n",
            "   2: company = 'GOOG'\n",
            "   3: data = pd_reader.DataReader(\n",
            "   4:   '{}'.format(company),\n",
            "   5:   'yahoo')\n",
            "   6: data = data[['Adj Close','High','Open','Low','Volume']]\n",
            "   7: data[\"return\"] = np.log(1+((data[\"Adj Close\"]-data[\"Adj Close\"].shift(1))/data[\"Adj Close\"].shift(1)))\n",
            "   8: data = data.dropna()\n",
            "   9: factor_ratio = 0.7\n",
            "  10: data_1 = data.iloc[:round(len(data)*factor_ratio)]\n",
            "  11: data_2 = data[round(len(data)*factor_ratio):]\n",
            "  12: \n",
            "  13: ###############################################\n",
            "  14: ##  Feature engineering construct the retrun ##\n",
            "  15: ###############################################\n",
            "  16: training_set = data_1.iloc[:,0:-1].values\n",
            "  17: y_set = data_1[\"return\"].values\n",
            "  18: y_set = y_set.reshape(-1,1)\n",
            "  19: sc = MinMaxScaler()\n",
            "  20: #training_set_scaled =training_set\n",
            "  21: \n",
            "  22: y_set_scaled=y_set\n",
            "  23: training_set_scaled = sc.fit_transform(training_set)\n",
            "  24: #y_set_scaled = sc.fit_transform(y_set)\n",
            "  25: \n",
            "  26: X_train = []\n",
            "  27: y_train = []\n",
            "  28: \n",
            "  29: for i in range(45, len(training_set_scaled)):\n",
            "  30:   X_train.append(training_set[i-45:i])\n",
            "  31:   y_train.append(y_set_scaled[i][0])\n",
            "  32: \n",
            "  33: X_train, y_train = np.array(X_train), np.array(y_train)\n",
            "  34: X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 5))\n",
            "  35: \n",
            "  36: #test set\n",
            "  37: y_test = data_2['return'].values\n",
            "  38: \n",
            "  39: dataset_total = data.iloc[:,0:-1]\n",
            "  40: inputs = dataset_total[len(dataset_total) - len(data_2) -45:].values\n",
            "  41: inputs = sc.fit_transform(inputs)\n",
            "  42: \n",
            "  43: X_test = []\n",
            "  44: for i in range(45, len(inputs)):\n",
            "  45:   X_test.append(inputs[i-45:i])\n",
            "  46: \n",
            "  47: X_test, y_test = np.array(X_test), np.array(y_test)\n",
            "  48: X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 5))\n",
            "  49: \n",
            "  50: \n",
            "  51: \n",
            "  52: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3: \n",
            "   4:   \"\"\"\n",
            "   5:   Model providing function:\n",
            "   6: \n",
            "   7:   Create Keras model with double curly brackets dropped-in as needed.\n",
            "   8:   Return value has to be a valid python dictionary with two customary keys:\n",
            "   9:       - loss: Specify a numeric evaluation metric to be minimized\n",
            "  10:       - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
            "  11:   The last one is optional, though recommended, namely:\n",
            "  12:       - model: specify the model just created so that we can later use it again.\n",
            "  13:   \"\"\"\n",
            "  14: \n",
            "  15:   model = Sequential()\n",
            "  16:   model.add(LSTM(units=space['units'], input_shape=(45,5),go_backwards= True, return_sequences= True))\n",
            "  17:   model.add(Dropout(rate=space['rate']))\n",
            "  18:   \n",
            "  19:   model.add(LSTM(units=space['units_1'], return_sequences= False))\n",
            "  20:   model.add(Dropout(rate=space['rate_1']))\n",
            "  21:   \n",
            "  22:   #model.add(LSTM(units=space['units_2'],go_backwards= True, return_sequences= False))\n",
            "  23:   #model.add(Dropout(rate=space['rate_2']))\n",
            "  24: \n",
            "  25:   #model.add(LSTM(units=space['units_3'], return_sequences= False))\n",
            "  26:   #model.add(Dropout(rate=space['rate_3']))\n",
            "  27:   \n",
            "  28:   #model.add(LSTM(units=space['units_4']))\n",
            "  29:   #model.add(Dropout(rate=space['rate_4']))\n",
            "  30:   \n",
            "  31:   model.add(Dense(space['Dense']))\n",
            "  32:   model.add(Dense(space['Dense_1']))\n",
            "  33:   model.add(Dense(1))\n",
            "  34: \n",
            "  35:   model.compile(loss='mean_squared_error',\n",
            "  36:                 optimizer=space['optimizer'])\n",
            "  37: \n",
            "  38:   model.summary()\n",
            "  39: \n",
            "  40:   result = model.fit(X_train, y_train,\n",
            "  41:             batch_size=space['batch_size'],\n",
            "  42:             epochs=40, verbose=2)\n",
            "  43:   #get the highest validation accuracy of the training epochs\n",
            "  44:   validation_error = np.amin(result.history['loss']) \n",
            "  45:   print('Best validation error of epoch:', validation_error)\n",
            "  46:   return {'loss': -validation_error, 'status': STATUS_OK, 'model': model}\n",
            "  47: \n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 45, 200)           164800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 45, 200)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 300)               601200    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1505      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 767,576\n",
            "Trainable params: 767,576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/40\n",
            " - 7s - loss: 0.1687\n",
            "\n",
            "Epoch 2/40\n",
            " - 3s - loss: 0.0052\n",
            "\n",
            "Epoch 3/40\n",
            " - 3s - loss: 9.3160e-04\n",
            "\n",
            "Epoch 4/40\n",
            " - 3s - loss: 5.6539e-04\n",
            "\n",
            "Epoch 5/40\n",
            " - 3s - loss: 4.9538e-04\n",
            "\n",
            "Epoch 6/40\n",
            " - 3s - loss: 5.6028e-04\n",
            "\n",
            "Epoch 7/40\n",
            " - 3s - loss: 5.1316e-04\n",
            "\n",
            "Epoch 8/40\n",
            " - 3s - loss: 4.9135e-04\n",
            "\n",
            "Epoch 9/40\n",
            " - 3s - loss: 5.0557e-04\n",
            "\n",
            "Epoch 10/40\n",
            " - 3s - loss: 4.8318e-04\n",
            "\n",
            "Epoch 11/40\n",
            " - 3s - loss: 5.0020e-04\n",
            "\n",
            "Epoch 12/40\n",
            " - 3s - loss: 4.4014e-04\n",
            "\n",
            "Epoch 13/40\n",
            " - 3s - loss: 4.6302e-04\n",
            "\n",
            "Epoch 14/40\n",
            " - 3s - loss: 4.6869e-04\n",
            "\n",
            "Epoch 15/40\n",
            " - 3s - loss: 4.8756e-04\n",
            "\n",
            "Epoch 16/40\n",
            " - 3s - loss: 4.3679e-04\n",
            "\n",
            "Epoch 17/40\n",
            " - 3s - loss: 4.6473e-04\n",
            "\n",
            "Epoch 18/40\n",
            " - 3s - loss: 4.6064e-04\n",
            "\n",
            "Epoch 19/40\n",
            " - 3s - loss: 4.6116e-04\n",
            "\n",
            "Epoch 20/40\n",
            " - 3s - loss: 4.0178e-04\n",
            "\n",
            "Epoch 21/40\n",
            " - 3s - loss: 4.5124e-04\n",
            "\n",
            "Epoch 22/40\n",
            " - 3s - loss: 4.4034e-04\n",
            "\n",
            "Epoch 23/40\n",
            " - 3s - loss: 4.1261e-04\n",
            "\n",
            "Epoch 24/40\n",
            " - 3s - loss: 4.1332e-04\n",
            "\n",
            "Epoch 25/40\n",
            " - 3s - loss: 4.2574e-04\n",
            "\n",
            "Epoch 26/40\n",
            " - 3s - loss: 3.9115e-04\n",
            "\n",
            "Epoch 27/40\n",
            " - 3s - loss: 4.0205e-04\n",
            "\n",
            "Epoch 28/40\n",
            " - 3s - loss: 4.0508e-04\n",
            "\n",
            "Epoch 29/40\n",
            " - 3s - loss: 3.7107e-04\n",
            "\n",
            "Epoch 30/40\n",
            " - 3s - loss: 4.2588e-04\n",
            "\n",
            "Epoch 31/40\n",
            " - 3s - loss: 4.1303e-04\n",
            "\n",
            "Epoch 32/40\n",
            " - 3s - loss: 3.8539e-04\n",
            "\n",
            "Epoch 33/40\n",
            " - 3s - loss: 3.8283e-04\n",
            "\n",
            "Epoch 34/40\n",
            " - 3s - loss: 3.6652e-04\n",
            "\n",
            "Epoch 35/40\n",
            " - 3s - loss: 3.7482e-04\n",
            "\n",
            "Epoch 36/40\n",
            " - 3s - loss: 3.4644e-04\n",
            "\n",
            "Epoch 37/40\n",
            " - 3s - loss: 3.5986e-04\n",
            "\n",
            "Epoch 38/40\n",
            " - 3s - loss: 3.6117e-04\n",
            "\n",
            "Epoch 39/40\n",
            " - 3s - loss: 3.5796e-04\n",
            "\n",
            "Epoch 40/40\n",
            " - 3s - loss: 3.5161e-04\n",
            "\n",
            "Best validation error of epoch:\n",
            "0.0003464378910037972\n",
            "100%|██████████| 1/1 [01:52<00:00, 112.16s/it, best loss: -0.0003464378910037972]\n",
            "Evalutation of best performing model:\n",
            "<keras.engine.sequential.Sequential object at 0x7f13bb40ea20>\n",
            "Best performing model chosen hyper-parameters:\n",
            "{'Dense': 2, 'Dense_1': 1, 'batch_size': 2, 'optimizer': 0, 'rate': 0.07582744887138203, 'rate_1': 0.015229584243240595, 'rate_2': 0.114254892109782, 'rate_3': 0.45350896294219734, 'rate_4': 0.38326289278437076, 'units': 1, 'units_1': 2, 'units_2': 0, 'units_3': 1, 'units_4': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyo4NHdqyh-n",
        "colab_type": "code",
        "outputId": "7aa2c88c-0858-4aca-9c19-c0ebf32e4329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "best_run"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dense': 2,\n",
              " 'Dense_1': 1,\n",
              " 'batch_size': 2,\n",
              " 'optimizer': 0,\n",
              " 'rate': 0.07582744887138203,\n",
              " 'rate_1': 0.015229584243240595,\n",
              " 'rate_2': 0.114254892109782,\n",
              " 'rate_3': 0.45350896294219734,\n",
              " 'rate_4': 0.38326289278437076,\n",
              " 'units': 1,\n",
              " 'units_1': 2,\n",
              " 'units_2': 0,\n",
              " 'units_3': 1,\n",
              " 'units_4': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7ZzZ2-PHyh-p",
        "colab_type": "code",
        "outputId": "43850584-e892-4610-dfb1-cae6b887976e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "best_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 45, 200)           164800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 45, 200)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 300)               601200    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1505      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 767,576\n",
            "Trainable params: 767,576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLJZi8Hjyh-q",
        "colab_type": "text"
      },
      "source": [
        "## Make sure to edit your stock ticker again in the next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa_aX3gvyh-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##maka sure to change the stock ticker here \n",
        "## add company ticker\n",
        "company = 'GOOG'\n",
        "data = pd_reader.DataReader(\n",
        "     '{}'.format(company),\n",
        "     'yahoo')\n",
        "data = data[['Adj Close','High','Open','Low','Volume']]\n",
        "data[\"return\"] = np.log(1+((data[\"Adj Close\"]-data[\"Adj Close\"].shift(1))/data[\"Adj Close\"].shift(1)))\n",
        "data = data.dropna()\n",
        "factor_ratio = 0.7\n",
        "data_1 = data.iloc[:round(len(data)*factor_ratio)]\n",
        "data_2 = data[round(len(data)*factor_ratio):]\n",
        " \n",
        "training_set = data_1.iloc[:,0:-1].values\n",
        "y_set = data_1[\"return\"].values\n",
        "y_set = y_set.reshape(-1,1)\n",
        "sc = MinMaxScaler()\n",
        "y_set_scaled = y_set\n",
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alb_Bonxyh-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_stock_price = data_2['return'].values\n",
        "\n",
        "dataset_total = data.iloc[:,0:-1]\n",
        "inputs = dataset_total[len(dataset_total) - len(data_2) -45:].values\n",
        "inputs = sc.fit_transform(inputs)\n",
        "\n",
        "X_test = []\n",
        "for i in range(45, len(inputs)):\n",
        "    X_test.append(inputs[i-45:i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "414zI9ISyh-s",
        "colab_type": "code",
        "outputId": "3f532a96-4096-48ed-9d87-033a8f1f3aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 5))\n",
        "X_test.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(758, 45, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VaNcjScYyh-v",
        "colab_type": "code",
        "outputId": "ad59db07-44f6-4591-c0ee-36ec46f101ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predicted_stock_price= best_model.predict(X_test)\n",
        "predicted_stock = pd.DataFrame(predicted_stock_price,columns=['perdict return'])\n",
        "real_stock = pd.DataFrame(real_stock_price,columns=['real return'])\n",
        "data_test = data[round(len(data)*factor_ratio):]\n",
        "data_test.reset_index(inplace=True)\n",
        "data_test = data_test[['Date']]\n",
        "\n",
        "final = pd.merge(real_stock, predicted_stock, left_index=True, right_index=True)\n",
        "final1 = pd.merge(data_test, final, left_index=True, right_index=True)\n",
        "final1.to_csv(\"{}.csv\".format(company))\n",
        "final['direction'] = final[\"real return\"]*final[\"perdict return\"]\n",
        "def iden(x):\n",
        "    if x >0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "final[\"hit\"] = final[\"direction\"].apply(lambda x:iden(x))\n",
        "print('hit ratio:{}'.format(final[\"hit\"].sum()/final[\"hit\"].count()))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hit ratio:0.5237467018469657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzElYx-nyh-x",
        "colab_type": "code",
        "outputId": "02a53580-b457-4d72-d8f4-c869e1040941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(real_stock_price, color = 'black', label = '{} Stock Price'.format(company))\n",
        "plt.plot(predicted_stock_price, color = 'green', label = 'Predicted {} Stock return'.format(company))\n",
        "plt.title('{} Stock return Prediction'.format(company))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('{} Stock return'.format(company))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEO8DPvoGn2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('GOOG_model.pickle','wb') as f:\n",
        "    pickle.dump(best_model,f)\n",
        "\n",
        "with open('GOOG_model.pickle','rb') as f:\n",
        "    model = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lbroo87JvWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "#files.download('GOOG_model.pickle') \n",
        "files.download(\"GOOG.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}